{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff4084e2-5721-45a6-9ff7-2c6273a5ae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "block_size = 8\n",
    "batch_size = 4\n",
    "learning_rate = 3e-4\n",
    "max_iters = 1000\n",
    "eval_iters = 250\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bfebda1-8acc-49a9-8158-230fac17efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] \n",
      " 74\n",
      "Folk lore, legends, myths and fairy tales have followed childhood\n",
      "through the ages, for every healthy youngster has a wholesome and\n",
      "instinctive love for stories fantastic, marvelous and manifestly\n",
      "unreal. The winged fairies of Grimm and Andersen have brought more\n",
      "happiness to childish hearts than all other human creations.\n",
      "\n",
      "Yet the old-time fairy tale, having served for generations, may\n",
      "now be classed as \"historical\" in the children's library; for the\n",
      "time has come for a s \n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('wizard_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = text[477:]\n",
    "chars = sorted(set(text))\n",
    "vocab_size = len(chars)\n",
    "print(chars,\"\\n\",len(chars))\n",
    "print(text[:477],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ebd0ca2-e580-44cc-9718-8e47ee607a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fine tuning'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_to_int = {ch:i for i,ch in enumerate(chars) }\n",
    "int_to_string = {i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "\n",
    "\n",
    "decode(encode('Fine tuning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c30eb90a-9af2-4449-a232-ce7bdb3d4f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([24, 62, 59, 58,  1, 59, 62, 65, 52,  9,  1, 59, 52, 54, 52, 61, 51, 66,\n",
       "         9,  1, 60, 72, 67, 55, 66,  1, 48, 61, 51,  1, 53, 48, 56, 65, 72,  1,\n",
       "        67, 48, 59, 52, 66,  1, 55, 48, 69, 52,  1, 53, 62, 59, 59, 62, 70, 52,\n",
       "        51,  1, 50, 55, 56, 59, 51, 55, 62, 62, 51,  0, 67, 55, 65, 62, 68, 54,\n",
       "        55,  1, 67, 55, 52,  1, 48, 54, 52, 66,  9,  1, 53, 62, 65,  1, 52, 69,\n",
       "        52, 65, 72,  1, 55, 52, 48, 59, 67, 55])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(encode(text),dtype=torch.long)\n",
    "data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2822c67f-c621-48c1-95ee-40d9714192a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      " tensor([[ 1, 33, 73,  9,  1, 48, 61, 51],\n",
      "        [62, 65, 62, 67, 55, 72,  1, 59],\n",
      "        [ 1, 66, 52, 61, 67,  1, 67, 55],\n",
      "        [ 1,  1,  1,  1,  1,  1,  1,  1]], device='cuda:0') \n",
      " targets:\n",
      " tensor([[33, 73,  9,  1, 48, 61, 51,  1],\n",
      "        [65, 62, 67, 55, 72,  1, 59, 52],\n",
      "        [66, 52, 61, 67,  1, 67, 55, 52],\n",
      "        [ 1,  1,  1,  1,  1,  1,  1,  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x,y = x.to(device), y.to(device)\n",
    "    return x,y\n",
    "\n",
    "x,y = get_batch('train')\n",
    "print('inputs:\\n',x,'\\n','targets:\\n',y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ace84ed8-3067-4b3f-9d91-ceb6eedb4312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([24]) taget is tensor(62)\n",
      "when input is tensor([24, 62]) taget is tensor(59)\n",
      "when input is tensor([24, 62, 59]) taget is tensor(58)\n",
      "when input is tensor([24, 62, 59, 58]) taget is tensor(1)\n",
      "when input is tensor([24, 62, 59, 58,  1]) taget is tensor(59)\n",
      "when input is tensor([24, 62, 59, 58,  1, 59]) taget is tensor(62)\n",
      "when input is tensor([24, 62, 59, 58,  1, 59, 62]) taget is tensor(65)\n",
      "when input is tensor([24, 62, 59, 58,  1, 59, 62, 65]) taget is tensor(52)\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print('when input is',context,'taget is',target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1540a9f-7bf9-44b2-95c5-5ab11595f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dc95c54-7e2b-47ce-bfb1-8f3f41027966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 8nSaI0oZb!_DbqVf*-\n",
      " N)cuzC(*0Rhv-gk\"AmZ!Bi1.,WRoelowC(zYEE: y0lK:&La0a)fT:*FM-U.c!A0r'J?SZL;eB.qYRTztEbxq*LW0(0YTzdlFyX,*pB(reo(Hmq:0eBRorx,c8m_C)C\"MKE_,P\"I,Wc(RT!,WPX.LmgB\n",
      "C-l.v.QICAMdeAW*]yHdI0tE8pxv!mxeez9yREfchb]?![mbEleAw-MZ?Lw]JEkNxoOM:*BvCdUs\n",
      "OmiVN&eeS1njdumoL!P8JjGLIa[nqbxKp0\"tJG lKcd?]sl.kh.LMxw;wxYRohr[znpy89V(pbnAnpSWQ\n",
      "uK\n",
      " z!UTFEkdbldHvLpLRo8AViBqyf'OeM8xe*.1BoYnM)CfS&Gw]xK,K&_)G(.,& zJRVdoZZ0:k\"sE?!IOikJ,KHcvFpPVae?oO&8iY[Laci)bXK(.v,h_Kuq)C*ApdLje8 GtxssM*]?]c9GJHI:k\"XEg&weAp.,PvR\"\n"
     ]
    }
   ],
   "source": [
    "class BiagramLanguageModel(nn.Module):\n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "\n",
    "    def forward(self,index,targets):\n",
    "        logits = self.token_embedding_table(index)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else :\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, index, max_new_tokens):\n",
    "        #index is (B,T) array if indices in the currrent context \n",
    "        for _ in range(max_new_tokens):\n",
    "            #get the preds\n",
    "            logits, loss = self.forward(index,None)\n",
    "            #focus only on the last time step\n",
    "            logits = logits[:, -1, :] #becomes (B,C)\n",
    "            #apply softmax\n",
    "            probs = F.softmax(logits,dim=-1)#(B, C)\n",
    "            index_next = torch.multinomial(probs,num_samples=1) #(B, 1)\n",
    "            #append samples into running swquence\n",
    "            index = torch.cat((index,index_next),dim=1) # (B, T+1)\n",
    "        return index\n",
    "\n",
    "model = BiagramLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "\n",
    "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
    "generated_chars = decode(m.generate(context,max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f65f679-02f1-4201-b98b-54d8e8282b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 | train loss: 4.7438 | val loss: 4.7636\n",
      "step: 250 | train loss: 4.6838 | val loss: 4.6951\n",
      "step: 500 | train loss: 4.6343 | val loss: 4.6464\n",
      "step: 750 | train loss: 4.5751 | val loss: 4.5599\n",
      "4.651147842407227\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate)\n",
    "for iter in range(max_iters):\n",
    "    if iter % eval_iters == 0:\n",
    "        losses = estimate_loss()\n",
    "        print(f'step: {iter} | train loss: {losses['train']:.4f} | val loss: {losses['val']:.4f}')\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    logits,loss = model.forward(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ec787ef-3249-40d5-aef9-6d21ced22f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1dO&_.r; ikx KanJ\"'wcU_,YA(ecSWvh.qK?pGFygV:nl:*-a9U8YsDsaZ*kuoNRYkxY&\n",
      "_nN[\"noh)?VAleeBiM [W9AWvFPVQ!,X.q[R8H:(z8GUhpxgzdKaiKb1.z0c\"r\"r\n",
      "h)'N0!f.WVF  a9Lan:v!cwnW)PBSwhL;UmpdgHv-nvBifcwOMo,G&)SuhK9[ocwf\n",
      "D NIn'8YeTXKjC_dL[)b_Y[R\n",
      "&rBtyl)foZ&xRW[u]RoJnqQnq0\"u8ifP\"pBanlBl.TV]?Dcvb!zCFfP'issyYU?_aEZ\"s\n",
      "I--EP&M)CK)bjcwz1HiBw,'S]bxh._KxC!HOjOtnnd'z1nlvHp?LiVFSXEEMFiR'\n",
      "z1dxYXqm0\"k1nD\n",
      "hpxwm&x[ub1&fh_o:n;xqHI,*&Nj'i0Wq_hp'kL.LAEyeWny\"t1dGJBlibxgRTAw1j-MgvQBw1aEI'X-fI:M_]o\n",
      "_'EDzfAF\"WKAr[jyRo[)! -'Fm_NPFb!Wfg\n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1,1),dtype=torch.long,device=device)\n",
    "generated_chars = decode(m.generate(context,max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a8677-7078-4465-8a27-3d19abdf3c31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
